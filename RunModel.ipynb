{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TestPath = '/content/drive/My Drive/Test'\n",
    "# OutputFile = '/content/drive/My Drive/Output.txt'\n",
    "TestPath = \"./Test\"\n",
    "OutputFile = \"./Output.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import Image\n",
    "import os\n",
    "from skimage import io\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "from skimage.transform import resize as io_resize\n",
    "import cv2\n",
    "import json\n",
    "import datetime\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = [os.path.join(TestPath, name) for name in os.listdir(TestPath)]\n",
    "RESIZE = (400, 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T1Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    This is to use with array of files and array of labels as an input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = io.imread(self.X[idx])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        if self.y is None:\n",
    "            return (image, idx)\n",
    "        return (image, self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = T.Compose(\n",
    "    [\n",
    "        T.ToPILImage(),\n",
    "        T.ToTensor(),\n",
    "        T.Resize(RESIZE),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = T1Dataset(img_files, None, transformer)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    for inputs,_ in tqdm(dataloader, desc=\"Testing\"):\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        predictions.append(preds.item())\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aacf64b653564f16a87e5888d836ebb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "model = pkl.load(open(\"./DeepModel.pkl\", \"rb\"))\n",
    "predictions = predict(model, loader)\n",
    "print(predictions)\n",
    "\n",
    "with open(OutputFile, \"w\") as f:\n",
    "    for pred in predictions:\n",
    "        f.write(str(pred) + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
