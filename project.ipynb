{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports \n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from feature_extraction import *\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from images\n",
    "is_load = True\n",
    "contours = []\n",
    "labels   = []  # 1 for males  , 0 for females\n",
    "\n",
    "if ( not is_load):\n",
    "    # read male images\n",
    "    male_path   = 'dataset_resized/flooded'\n",
    "    male_files   = [ f for f in listdir(male_path) if isfile(join(male_path,f)) ]\n",
    "    for i in tqdm(range(0, len(male_files))):\n",
    "        img  = Image.open(join(male_path,male_files[i]))\n",
    "        img, _  = preprocess_image( img )\n",
    "        contour = get_contour_pixels(img)\n",
    "        contours.append(contour)\n",
    "        labels.append(1)\n",
    "        \n",
    "    ## read female images\n",
    "    female_path = 'dataset_resized/non-flooded'\n",
    "    female_files = [ f for f in listdir(female_path) if isfile(join(female_path,f)) ]\n",
    "    for i in tqdm(range(0, len(female_files))):\n",
    "        img  = Image.open( join(female_path,female_files[i]))\n",
    "        img, _  = preprocess_image( img )\n",
    "        contour = get_contour_pixels(img)\n",
    "        contours.append(contour)\n",
    "        labels.append(0)\n",
    "\n",
    "    contours = np.asarray(contours , dtype= object)\n",
    "    labels   = np.asarray(labels   , dtype= int )\n",
    "    #save lables to dataset\n",
    "    np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinge_features = []\n",
    "cold_features  = []\n",
    "if(not is_load):\n",
    "    for i in tqdm(range( len(contours)) ):\n",
    "        feature  = get_hinge_features( contours[i] )\n",
    "        hinge_features.append(feature)  \n",
    "    hinge_features = np.asarray(hinge_features , dtype=object)\n",
    "    np.save('features/hinge_features.npy', hinge_features)\n",
    "\n",
    "    for i in tqdm(range( len(contours)) ):\n",
    "        feature  = get_cold_features( contours[i] )\n",
    "        cold_features.append(feature)  \n",
    "    cold_features = np.asarray(cold_features , dtype=object)\n",
    "    np.save('features/cold_features.npy', cold_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(is_load):\n",
    "    hinge_features = np.load('features/hinge_features.npy' , allow_pickle= True)\n",
    "    cold_features = np.load('features/cold_features.npy' ,  allow_pickle= True)\n",
    "    labels = np.load('features/labels.npy' , allow_pickle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(922, 420)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate features in one flattened array\n",
    "features = np.concatenate( (hinge_features, cold_features) , axis=1)\n",
    "cold_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split( hinge_features , labels , test_size=0.2 ,  random_state=109) # 80% training and 20% test\n",
    "# X_train, X_test, y_train, y_test = train_test_split( hinge_features , labels , test_size=0.2 ,  random_state=50)\n",
    "X_train, X_test, y_train, y_test = train_test_split( features , labels , test_size=0.2 ,  random_state=175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Applying PCA function on training\n",
    "# # and testing set of X component\n",
    "# from sklearn.decomposition import PCA\n",
    " \n",
    "# pca = PCA(n_components = 0.95)\n",
    " \n",
    "# # X_train = pca.fit_transform(X_train)\n",
    "# # X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train the model: in milliseconds:  165.3447151184082\n",
      "Accuracy: 0.6864864864864865\n"
     ]
    }
   ],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Create a svm Classifier\n",
    "t0 = time.time()\n",
    "SVM_clf = svm.SVC(kernel= \"linear\" ) # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "SVM_clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = SVM_clf.predict(X_test)\n",
    "t1 = time.time()\n",
    "# clf.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# accuracy & time taken to train the model\n",
    "print(\"Time taken to train the model: in milliseconds: \", (t1-t0)*1000)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m## make and xgboost model   (pip install xgboost)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxgb\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# create classifier \u001b[39;00m\n\u001b[1;32m      5\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "## make and xgboost model   (pip install xgboost)\n",
    "import xgboost as xgb\n",
    "\n",
    "# create classifier \n",
    "t0 = time.time()\n",
    "XGB_clf = xgb.XGBClassifier(max_depth=3, n_estimators=1000, learning_rate=0.05)\n",
    "# XGB_clf = xgb.XGBClassifier(max_depth=5, n_estimators=5000, learning_rate=0.05)\n",
    "\n",
    "# fit the classifier on the training data\n",
    "XGB_clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for the test data\n",
    "y_pred = XGB_clf.predict(X_test)\n",
    "t1 = time.time()\n",
    "\n",
    "# accuracy & time taken to train the model\n",
    "print(\"Time taken to train the model: in milliseconds: \", (t1-t0)*1000, \"ms\")\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train the model: in milliseconds:  165.3447151184082 ms\n",
      "Accuracy: 0.8864864864864865\n"
     ]
    }
   ],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Create a Gaussian Classifier  , random_state -> 39 , 60 , 67\n",
    "# randomFores_clf=RandomForestClassifier(n_estimators=1000,  random_state = 67)\n",
    "\n",
    "#Train the model using the training sets \n",
    "# randomFores_clf.fit(X_train,y_train)\n",
    "\n",
    "# y_pred=randomFores_clf.predict(X_test)\n",
    "# # Create the parameter grid based on the results of random search\n",
    "param_grid = {\n",
    "    'max_depth': [10, 50, 100],\n",
    "    'min_samples_leaf': [1, 2,5],\n",
    "    'min_samples_split': [1, 2, 5],\n",
    "    'n_estimators': [10,20, 100, 200]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "pipe= Pipeline([('scaler', StandardScaler()), ('rf', RandomForestClassifier())])\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# accuracy & time taken to train the model\n",
    "print(\"Time taken to train the model: in milliseconds: \", (t1-t0)*1000, \"ms\")\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(classifier , random=None) :\n",
    "    if random is None :\n",
    "        X_train, X_test, y_train, y_test = train_test_split( hinge_features , labels , test_size=0.2)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split( hinge_features , labels , test_size=0.2, random_state=random ) # 80% training and 20% test\n",
    "    #Train the model using the training sets\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    return metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train SVM: in miutes 0.008482722441355388 minutes\n",
      "Time taken to train XGBOOST: in miutes 1.6525152762730917 minutes\n",
      "Time taken to train Random forest: in miutes 2.960528488953908 minutes\n"
     ]
    }
   ],
   "source": [
    "# Get avg accuraccy for models ( SVM , XGB , Random Forest)\n",
    "is_get_avg = False \n",
    "if is_get_avg: \n",
    "    svm_list = []\n",
    "    xgb_list = []\n",
    "    rf_list  = []\n",
    "    time_list = []\n",
    "\n",
    "    # train svm model for 100 times\n",
    "    t0 = time.time()\n",
    "    for i in tqdm(range(100, 200)):\n",
    "        svm_list.append( train(SVM_clf ) )\n",
    "    t1 = time.time()\n",
    "    time_list.append( (t1-t0) )\n",
    "\n",
    "    # train xgboost model for 100 times\n",
    "    t0 = time.time()\n",
    "    for i in tqdm(range(100, 200)):\n",
    "        xgb_list.append( train(XGB_clf) )\n",
    "    t1 = time.time()\n",
    "    time_list.append( (t1-t0) )\n",
    "    \n",
    "    # train random forest model for 100 times\n",
    "    t0 = time.time()\n",
    "    for i in tqdm(range(100, 200)):\n",
    "        rf_list.append ( train(randomFores_clf ))\n",
    "    t1 = time.time()\n",
    "    time_list.append( (t1-t0) )\n",
    "\n",
    "print(\"Time taken to train SVM: in miutes\", time_list[0]/60, \"minutes\")\n",
    "print(\"Time taken to train XGBOOST: in miutes\", time_list[1]/60, \"minutes\")\n",
    "print(\"Time taken to train Random forest: in miutes\", time_list[2]/60, \"minutes\")\n",
    "avg_svm = sum(svm_list) / len(svm_list)\n",
    "avg_xgb = sum(xgb_list) / len(xgb_list)\n",
    "avg_rf  = sum(rf_list)  / len(rf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " avg SVM 0.641232876712329 || max SVM 0.7534246575342466 || min SVM 0.4931506849315068 || argmax 69\n",
      " avg XGB 0.8000000000000002 || max XGB 0.8767123287671232 || min XGB 0.6712328767123288 || argmax 2\n",
      " avg RF  0.7875342465753427  || max RF  0.8904109589041096  || min RF  0.6712328767123288  || argmax 78\n"
     ]
    }
   ],
   "source": [
    "if is_get_avg:\n",
    "    print(f\" avg SVM {avg_svm} || max SVM {max(svm_list)} || min SVM {min(svm_list)} || argmax {np.array(svm_list).argmax()}\")\n",
    "    print(f\" avg XGB {avg_xgb} || max XGB {max(xgb_list)} || min XGB {min(xgb_list)} || argmax {np.array(xgb_list).argmax()}\")\n",
    "    print(f\" avg RF  {avg_rf}  || max RF  {max(rf_list)}  || min RF  {min(rf_list)}  || argmax {np.array(rf_list).argmax() }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_img_hinge( classifier , path):\n",
    "    img  = Image.open(path)\n",
    "    img, _  = preprocess_image(  img)\n",
    "    contour = get_contour_pixels(img)\n",
    "    hinge = get_hinge_features(contour)\n",
    "    tt    = classifier.predict(np.array([hinge]))\n",
    "    if tt == 1 : print(f\"{path} \\t: is Male\") \n",
    "    else       : print(f\"{path} \\t: is Female\") \n",
    "\n",
    "# def test_img_cold( classifier , path):\n",
    "#     img  = Image.open(path)\n",
    "#     img, _  = preprocess_image(  img)\n",
    "#     contour = get_contour_pixels(img)\n",
    "#     cold  = get_cold_features(contour)\n",
    "#     tt    = classifier.predict(np.array([cold]))\n",
    "#     if tt == 1 : print(f\"{path} \\t: is Male\") \n",
    "#     else       : print(f\"{path} \\t: is Female\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test results in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Submission/test\\001.jpg \t: is Male\n",
      "Project Submission/test\\002.jpg \t: is Male\n",
      "Project Submission/test\\003.jpg \t: is Male\n",
      "Project Submission/test\\004.jpg \t: is Male\n",
      "Project Submission/test\\005.jpg \t: is Male\n",
      "Project Submission/test\\006.jpg \t: is Male\n",
      "------------------------------------------------\n",
      "Project Submission/test\\001.jpg \t: is Male\n",
      "Project Submission/test\\002.jpg \t: is Male\n",
      "Project Submission/test\\003.jpg \t: is Female\n",
      "Project Submission/test\\004.jpg \t: is Female\n",
      "Project Submission/test\\005.jpg \t: is Female\n",
      "Project Submission/test\\006.jpg \t: is Male\n",
      "------------------------------------------------\n",
      "Project Submission/test\\001.jpg \t: is Male\n",
      "Project Submission/test\\002.jpg \t: is Male\n",
      "Project Submission/test\\003.jpg \t: is Female\n",
      "Project Submission/test\\004.jpg \t: is Female\n",
      "Project Submission/test\\005.jpg \t: is Female\n",
      "Project Submission/test\\006.jpg \t: is Male\n"
     ]
    }
   ],
   "source": [
    "# test_img_hinge( XGB_clf, '/001.jpg')\n",
    "# test_img_hinge( XGB_clf, 'dataSet/Females/F100.jpg')\n",
    "\n",
    "\n",
    "OUTPUT_DIRECTORY   = 'Project Submission/test'\n",
    "test_files   = [ f for f in listdir(OUTPUT_DIRECTORY) if isfile(join(OUTPUT_DIRECTORY,f)) ]\n",
    "for i in range(0, len(test_files)):\n",
    "    img  = Image.open(join(OUTPUT_DIRECTORY,test_files[i]))\n",
    "    test_img_hinge(SVM_clf , join(OUTPUT_DIRECTORY,test_files[i]))\n",
    "print('------------------------------------------------')\n",
    "\n",
    "for i in range(0, len(test_files)):\n",
    "    img  = Image.open(join(OUTPUT_DIRECTORY,test_files[i]))\n",
    "    test_img_hinge(XGB_clf , join(OUTPUT_DIRECTORY,test_files[i]))\n",
    "\n",
    "print('------------------------------------------------')\n",
    "for i in range(0, len(test_files)):\n",
    "    img  = Image.open(join(OUTPUT_DIRECTORY,test_files[i]))\n",
    "    test_img_hinge(randomFores_clf , join(OUTPUT_DIRECTORY,test_files[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:16<00:00,  2.73s/it]\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIRECTORY = \"Project Submission/out\" ## * Appended Path of outputs\n",
    "TEST_DIRECTORY   = \"Project Submission/test\" ## * Appended Path of test images\n",
    "answers   = []\n",
    "time_list =[]\n",
    "\n",
    "\n",
    "test_files   = [ f for f in listdir(TEST_DIRECTORY) if isfile(join(TEST_DIRECTORY,f)) ]\n",
    "for i in tqdm(range(0, len(test_files))):\n",
    "    img  = Image.open(join(TEST_DIRECTORY,test_files[i]))\n",
    "    \n",
    "    t0 = time.time()\n",
    "    try: \n",
    "        img, _  = preprocess_image( img )\n",
    "        contour = get_contour_pixels(img)\n",
    "        hinge = get_hinge_features(contour)\n",
    "        ans    = randomFores_clf.predict(np.array([hinge]))\n",
    "        t1 = time.time()\n",
    "\n",
    "        time_list.append( (t1-t0) )\n",
    "        if   ans == 1 :   answers.append(1)\n",
    "        elif ans == 0 : answers.append(0)\n",
    "        else : answers.append(-1)\n",
    "    except:\n",
    "        print(f\"{test_files[i]} \\t: is not a valid image\")\n",
    "        answers.append(-1)\n",
    "        time_list.append( time.time() - t0 )\n",
    "\n",
    "# save the output in txt files \n",
    "with open(join(OUTPUT_DIRECTORY,'results.txt'), 'w') as f:\n",
    "    for i in range(0, len(answers)):\n",
    "        f.write(f\"{answers[i]}\\n\")\n",
    "\n",
    "#write time in txt files \n",
    "with open(join(OUTPUT_DIRECTORY,'times.txt'), 'w') as f:\n",
    "    for i in range(0, len(time_list)):\n",
    "        f.write(f\"{time_list[i]}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\t || \t2.726\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIRECTORY = \"Project Submission/out\" ## * Appended Path of outputs\n",
    "TEST_DIRECTORY   = \"Project Submission/test\" ## * Appended Path of test images\n",
    "truth = None\n",
    "with open('./ground_truth.txt', 'rb') as gt_file:\n",
    "    truth = [ int(line)  for line in gt_file.readlines()]\n",
    "    truth = np.array(truth)\n",
    "\n",
    "hypothesis = None\n",
    "with open( join(OUTPUT_DIRECTORY,'results.txt'), 'rb') as hypo_file:\n",
    "    hypothesis = [ int(line)  for line in hypo_file.readlines()]\n",
    "    hypothesis = np.array(hypothesis)\n",
    "\n",
    "## ! Account for length mismatch:\n",
    "if len(truth) != len(hypothesis):\n",
    "    truncation_len = min(len(truth), len(hypothesis))\n",
    "    hypothesis = hypothesis[:truncation_len]\n",
    "    truth = truth[:truncation_len]\n",
    "\n",
    "ACCUARICY = np.sum(truth == hypothesis) / len(truth)    \n",
    "\n",
    "## * Time Evaluation:\n",
    "times = None\n",
    "with open(join(OUTPUT_DIRECTORY,'times.txt'), 'rb') as times_file:\n",
    "\n",
    "    times = [float(line) for line in times_file.readlines()]\n",
    "    times = np.array(times)\n",
    "\n",
    "TIME_MEAN = round(np.mean(times), 3)\n",
    "\n",
    "\n",
    "## * Report:\n",
    "print(ACCUARICY*100  , TIME_MEAN , sep = \"\\t || \\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
